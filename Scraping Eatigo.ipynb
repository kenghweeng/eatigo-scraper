{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class RunChromeTests():\n",
    "    def test(self):\n",
    "        # After setting PATH in bash_profile:\n",
    "        shop_names, shop_location = [], []\n",
    "        # driverLocation = \"/Users/kenghweeng/Desktop/Selenium_Projects/chromedriver\"\n",
    "        # os.environ[\"webdriver.chrome.driver\"] = driverLocation\n",
    "        driver = webdriver.Chrome(\"/Users/kenghweeng/Desktop/Selenium_Projects/chromedriver\")\n",
    "        driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        for entry in soup.find_all(class_='minimal-card__title'):\n",
    "            shop_names.append(entry.text)\n",
    "        for entry in soup.find_all(class_='minimal-card__description'):\n",
    "            shop_location.append(entry.text)\n",
    "        df = pd.DataFrame.from_dict(dict(list(zip(shop_names, shop_location))), orient=\"index\")\n",
    "        df.to_csv(\"data.csv\")\n",
    "        \n",
    "        \n",
    "            \n",
    "chromed = RunChromeTests()\n",
    "chromed.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code starts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sg/singapore/en/r/-d-i-g-dining-in-garden-2833\n",
      "/sg/singapore/en/r/1001-of-arabia-5001899\n",
      "/sg/singapore/en/r/1864-sofitel-singapore-city-centre-3411\n",
      "/sg/singapore/en/r/1927-so-sofitel-5004571\n",
      "/sg/singapore/en/r/2211-mookata-5005941\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "driver = webdriver.Chrome(\"/Users/kenghweeng/Desktop/Selenium_Projects/chromedriver\")\n",
    "driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\") # website you want info from.\n",
    "content = driver.page_source\n",
    "soup = BeautifulSoup(content)\n",
    "\n",
    "for entry in soup.find_all(class_='minimal-card')[0:5]:\n",
    "    print(entry.get('href'))\n",
    "    link = \"https://eatigo.com\"\n",
    "    link = link + entry.get('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "class RunChromeTests():\n",
    "    def test(self):\n",
    "        # After setting PATH in bash_profile:\n",
    "        driver = webdriver.Chrome(\"/Users/kenghweeng/Desktop/Selenium_Projects/chromedriver\")\n",
    "        driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        \n",
    "        \n",
    "        final = []\n",
    "\n",
    "        for entry in soup.find_all(class_='minimal-card')[0:150]:\n",
    "#             driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "            lst, temp = [], {}\n",
    "            link = entry.get('href')\n",
    "#             https://eatigo.com/sg/singapore/en/r/1001-of-arabia-5001899\n",
    "            link = \"https://eatigo.com\" + link\n",
    "#             print(link)\n",
    "            lst.append(link)\n",
    "            driver.get(link)\n",
    "            content2 = driver.page_source\n",
    "            soup2 = BeautifulSoup(content2)\n",
    "            lst.append(soup2.find(class_='restaurant-section--header-title').text)\n",
    "            lst.append(soup2.find(class_='star-ratings').get('title'))\n",
    "            for a in soup2.find_all(class_='restaurant-content--information-item'):\n",
    "                lst.append(list(map(lambda x: x.text, a.find_all('li'))))\n",
    "                \n",
    "            for a in soup2.find_all(class_='discount-item--medium'):\n",
    "                temp[a.find('div', attrs={'class':'discount-item__first'}).text] = a.find('div', attrs={'class':'discount-item__second'}).text\n",
    "            lst.append(temp)\n",
    "            final.append(lst)\n",
    "        df = pd.DataFrame.from_records(final, columns = [\"link\", \"name\", \"rating\", \"address\", \"services\", \"payment\", \"atmosphere\", \"spoken_lang\", \"discount\"])\n",
    "        df.to_csv(\"mervin.csv\")\n",
    "        driver.close()\n",
    "        \n",
    "    def test2(self):\n",
    "        # After setting PATH in bash_profile:\n",
    "        driver = webdriver.Chrome(\"/Users/kenghweeng/Desktop/Selenium_Projects/chromedriver\")\n",
    "        driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        \n",
    "        \n",
    "        final = []\n",
    "\n",
    "        for entry in soup.find_all(class_='minimal-card')[150:300]:\n",
    "#             driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "            lst, temp = [], {}\n",
    "            link = entry.get('href')\n",
    "#             https://eatigo.com/sg/singapore/en/r/1001-of-arabia-5001899\n",
    "            link = \"https://eatigo.com\" + link\n",
    "#             print(link)\n",
    "            lst.append(link)\n",
    "            driver.get(link)\n",
    "            content2 = driver.page_source\n",
    "            soup2 = BeautifulSoup(content2)\n",
    "            lst.append(soup2.find(class_='restaurant-section--header-title').text)\n",
    "            lst.append(soup2.find(class_='star-ratings').get('title'))\n",
    "            for a in soup2.find_all(class_='restaurant-content--information-item'):\n",
    "                lst.append(list(map(lambda x: x.text, a.find_all('li'))))\n",
    "                \n",
    "            for a in soup2.find_all(class_='discount-item--medium'):\n",
    "                temp[a.find('div', attrs={'class':'discount-item__first'}).text] = a.find('div', attrs={'class':'discount-item__second'}).text\n",
    "            lst.append(temp)\n",
    "            final.append(lst)\n",
    "        df = pd.DataFrame.from_records(final, columns = [\"link\", \"name\", \"rating\", \"address\", \"services\", \"payment\", \"atmosphere\", \"spoken_lang\", \"discount\"])\n",
    "        df.to_csv(\"mervin2.csv\")\n",
    "        driver.close()\n",
    "        \n",
    "    def test3(self):\n",
    "        # After setting PATH in bash_profile:\n",
    "        driver = webdriver.Chrome(\"/Users/kenghweeng/Desktop/Selenium_Projects/chromedriver\")\n",
    "        driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        \n",
    "        \n",
    "        final = []\n",
    "\n",
    "        for entry in soup.find_all(class_='minimal-card')[300:350]:\n",
    "#             driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "            lst, temp = [], {}\n",
    "            link = entry.get('href')\n",
    "#             https://eatigo.com/sg/singapore/en/r/1001-of-arabia-5001899\n",
    "            link = \"https://eatigo.com\" + link\n",
    "#             print(link)\n",
    "            lst.append(link)\n",
    "            driver.get(link)\n",
    "            content2 = driver.page_source\n",
    "            soup2 = BeautifulSoup(content2)\n",
    "            lst.append(soup2.find(class_='restaurant-section--header-title').text)\n",
    "            lst.append(soup2.find(class_='star-ratings').get('title'))\n",
    "            for a in soup2.find_all(class_='restaurant-content--information-item'):\n",
    "                lst.append(list(map(lambda x: x.text, a.find_all('li'))))\n",
    "                \n",
    "            for a in soup2.find_all(class_='discount-item--medium'):\n",
    "                temp[a.find('div', attrs={'class':'discount-item__first'}).text] = a.find('div', attrs={'class':'discount-item__second'}).text\n",
    "            lst.append(temp)\n",
    "            final.append(lst)\n",
    "        df = pd.DataFrame.from_records(final, columns = [\"link\", \"name\", \"rating\", \"address\", \"services\", \"payment\", \"atmosphere\", \"spoken_lang\", \"discount\"])\n",
    "        df.to_csv(\"mervin3.csv\")\n",
    "        driver.close()\n",
    "    \n",
    "    \n",
    "        \n",
    "    def test4(self):\n",
    "        # After setting PATH in bash_profile:\n",
    "        driver = webdriver.Chrome(\"/Users/kenghweeng/Desktop/Selenium_Projects/chromedriver\")\n",
    "        driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        \n",
    "        \n",
    "        final = []\n",
    "\n",
    "        for entry in soup.find_all(class_='minimal-card')[350:400]:\n",
    "#             driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "            lst, temp = [], {}\n",
    "            link = entry.get('href')\n",
    "#             https://eatigo.com/sg/singapore/en/r/1001-of-arabia-5001899\n",
    "            link = \"https://eatigo.com\" + link\n",
    "#             print(link)\n",
    "            lst.append(link)\n",
    "            driver.get(link)\n",
    "            content2 = driver.page_source\n",
    "            soup2 = BeautifulSoup(content2)\n",
    "            lst.append(soup2.find(class_='restaurant-section--header-title').text)\n",
    "            lst.append(soup2.find(class_='star-ratings').get('title'))\n",
    "            for a in soup2.find_all(class_='restaurant-content--information-item'):\n",
    "                lst.append(list(map(lambda x: x.text, a.find_all('li'))))\n",
    "                \n",
    "            for a in soup2.find_all(class_='discount-item--medium'):\n",
    "                temp[a.find('div', attrs={'class':'discount-item__first'}).text] = a.find('div', attrs={'class':'discount-item__second'}).text\n",
    "            lst.append(temp)\n",
    "            final.append(lst)\n",
    "        df = pd.DataFrame.from_records(final, columns = [\"link\", \"name\", \"rating\", \"address\", \"services\", \"payment\", \"atmosphere\", \"spoken_lang\", \"discount\"])\n",
    "        df.to_csv(\"mervin4.csv\")\n",
    "        driver.close()\n",
    "        \n",
    "    def test5(self):\n",
    "        # After setting PATH in bash_profile:\n",
    "        driver = webdriver.Chrome(\"/Users/kenghweeng/Desktop/Selenium_Projects/chromedriver\")\n",
    "        driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        \n",
    "        \n",
    "        final = []\n",
    "\n",
    "        for entry in soup.find_all(class_='minimal-card')[400:450]:\n",
    "#             driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "            lst, temp = [], {}\n",
    "            link = entry.get('href')\n",
    "#             https://eatigo.com/sg/singapore/en/r/1001-of-arabia-5001899\n",
    "            link = \"https://eatigo.com\" + link\n",
    "#             print(link)\n",
    "            lst.append(link)\n",
    "            driver.get(link)\n",
    "            content2 = driver.page_source\n",
    "            soup2 = BeautifulSoup(content2)\n",
    "            lst.append(soup2.find(class_='restaurant-section--header-title').text)\n",
    "            lst.append(soup2.find(class_='star-ratings').get('title'))\n",
    "            for a in soup2.find_all(class_='restaurant-content--information-item'):\n",
    "                lst.append(list(map(lambda x: x.text, a.find_all('li'))))\n",
    "                \n",
    "            for a in soup2.find_all(class_='discount-item--medium'):\n",
    "                temp[a.find('div', attrs={'class':'discount-item__first'}).text] = a.find('div', attrs={'class':'discount-item__second'}).text\n",
    "            lst.append(temp)\n",
    "            final.append(lst)\n",
    "        df = pd.DataFrame.from_records(final, columns = [\"link\", \"name\", \"rating\", \"address\", \"services\", \"payment\", \"atmosphere\", \"spoken_lang\", \"discount\"])\n",
    "        df.to_csv(\"mervin5.csv\")\n",
    "        driver.close()\n",
    "        \n",
    "    def test6(self):\n",
    "        # After setting PATH in bash_profile:\n",
    "        driver = webdriver.Chrome(\"/Users/kenghweeng/Desktop/Selenium_Projects/chromedriver\")\n",
    "        driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        \n",
    "        \n",
    "        final = []\n",
    "\n",
    "        for entry in soup.find_all(class_='minimal-card')[450:500]:\n",
    "#             driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "            lst, temp = [], {}\n",
    "            link = entry.get('href')\n",
    "#             https://eatigo.com/sg/singapore/en/r/1001-of-arabia-5001899\n",
    "            link = \"https://eatigo.com\" + link\n",
    "#             print(link)\n",
    "            lst.append(link)\n",
    "            driver.get(link)\n",
    "            content2 = driver.page_source\n",
    "            soup2 = BeautifulSoup(content2)\n",
    "            lst.append(soup2.find(class_='restaurant-section--header-title').text)\n",
    "            lst.append(soup2.find(class_='star-ratings').get('title'))\n",
    "            for a in soup2.find_all(class_='restaurant-content--information-item'):\n",
    "                lst.append(list(map(lambda x: x.text, a.find_all('li'))))\n",
    "                \n",
    "            for a in soup2.find_all(class_='discount-item--medium'):\n",
    "                temp[a.find('div', attrs={'class':'discount-item__first'}).text] = a.find('div', attrs={'class':'discount-item__second'}).text\n",
    "            lst.append(temp)\n",
    "            final.append(lst)\n",
    "        df = pd.DataFrame.from_records(final, columns = [\"link\", \"name\", \"rating\", \"address\", \"services\", \"payment\", \"atmosphere\", \"spoken_lang\", \"discount\"])\n",
    "        df.to_csv(\"mervin6.csv\")\n",
    "        driver.close()\n",
    "        \n",
    "    def test7(self):\n",
    "        # After setting PATH in bash_profile:\n",
    "        driver = webdriver.Chrome(\"/Users/kenghweeng/Desktop/Selenium_Projects/chromedriver\")\n",
    "        driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        \n",
    "        \n",
    "        final = []\n",
    "\n",
    "        for entry in soup.find_all(class_='minimal-card')[500:550]:\n",
    "#             driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "            lst, temp = [], {}\n",
    "            link = entry.get('href')\n",
    "#             https://eatigo.com/sg/singapore/en/r/1001-of-arabia-5001899\n",
    "            link = \"https://eatigo.com\" + link\n",
    "#             print(link)\n",
    "            lst.append(link)\n",
    "            driver.get(link)\n",
    "            content2 = driver.page_source\n",
    "            soup2 = BeautifulSoup(content2)\n",
    "            lst.append(soup2.find(class_='restaurant-section--header-title').text)\n",
    "            lst.append(soup2.find(class_='star-ratings').get('title'))\n",
    "            for a in soup2.find_all(class_='restaurant-content--information-item'):\n",
    "                lst.append(list(map(lambda x: x.text, a.find_all('li'))))\n",
    "                \n",
    "            for a in soup2.find_all(class_='discount-item--medium'):\n",
    "                temp[a.find('div', attrs={'class':'discount-item__first'}).text] = a.find('div', attrs={'class':'discount-item__second'}).text\n",
    "            lst.append(temp)\n",
    "            final.append(lst)\n",
    "        df = pd.DataFrame.from_records(final, columns = [\"link\", \"name\", \"rating\", \"address\", \"services\", \"payment\", \"atmosphere\", \"spoken_lang\", \"discount\"])\n",
    "        df.to_csv(\"mervin7.csv\")\n",
    "        driver.close()\n",
    "            \n",
    "    def test8(self):\n",
    "        # After setting PATH in bash_profile:\n",
    "        driver = webdriver.Chrome(\"/Users/kenghweeng/Desktop/Selenium_Projects/chromedriver\")\n",
    "        driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "        content = driver.page_source\n",
    "        soup = BeautifulSoup(content)\n",
    "        \n",
    "        \n",
    "        final = []\n",
    "\n",
    "        for entry in soup.find_all(class_='minimal-card')[550:]:\n",
    "#             driver.get(\"https://eatigo.com/sg/singapore/en/view-all-a-z\")\n",
    "            lst, temp = [], {}\n",
    "            link = entry.get('href')\n",
    "#             https://eatigo.com/sg/singapore/en/r/1001-of-arabia-5001899\n",
    "            link = \"https://eatigo.com\" + link\n",
    "#             print(link)\n",
    "            lst.append(link)\n",
    "            driver.get(link)\n",
    "            content2 = driver.page_source\n",
    "            soup2 = BeautifulSoup(content2)\n",
    "            lst.append(soup2.find(class_='restaurant-section--header-title').text)\n",
    "            lst.append(soup2.find(class_='star-ratings').get('title'))\n",
    "            for a in soup2.find_all(class_='restaurant-content--information-item'):\n",
    "                lst.append(list(map(lambda x: x.text, a.find_all('li'))))\n",
    "                \n",
    "            for a in soup2.find_all(class_='discount-item--medium'):\n",
    "                temp[a.find('div', attrs={'class':'discount-item__first'}).text] = a.find('div', attrs={'class':'discount-item__second'}).text\n",
    "            lst.append(temp)\n",
    "            final.append(lst)\n",
    "        df = pd.DataFrame.from_records(final, columns = [\"link\", \"name\", \"rating\", \"address\", \"services\", \"payment\", \"atmosphere\", \"spoken_lang\", \"discount\"])\n",
    "        df.to_csv(\"mervin8.csv\")\n",
    "        driver.close()\n",
    "    \n",
    "        \n",
    "chromed = RunChromeTests()\n",
    "chromed.test()\n",
    "chromed.test2()\n",
    "chromed.test3()\n",
    "chromed.test4()\n",
    "chromed.test5()\n",
    "chromed.test6()\n",
    "chromed.test7()\n",
    "chromed.test8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
